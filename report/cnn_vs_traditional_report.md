# 基于CNN与传统机器学习模型的性状预测性能对比分析报告

## 1. 引言

在本项目中，我们对多个小麦性状（如sterilspike、FHB、spikelet等）进行了基于基因型数据的表型预测。采用的模型包括卷积神经网络（CNN）和传统机器学习方法（随机森林、XGBoost、LightGBM、Lasso）。本文将对比各模型在不同性状上的表现，并结合CNN的网络结构进行分析。

## 2. CNN网络结构简述

CNN模型的核心优势在于其能够自动提取输入数据中的局部特征，适合处理高维、结构化的基因型数据。  
（此处可插入网络结构图，建议引用`res/cnn/`目录下的结构示意图或训练过程可视化图片）

**网络结构参考：**
- 输入层：SNP特征向量
- 多层卷积层+池化层：提取局部特征
- 全连接层：综合特征
- 输出层：回归预测

（图片插入建议：  
![](res/cnn/结构示意图.png)  
如无结构图，可用训练曲线、特征热图等替代）

## 3. 各性状模型性能对比

数据来源：`trait_all_metrics.csv`，主要关注R2、RMSE、PearsonR等指标。

### 3.1 性状整体表现

| 性状         | 最优模型   | R2    | RMSE   | PearsonR | CNN最佳PearsonR |
|--------------|------------|-------|--------|----------|-----------------|
| sterilspike  | XGBoost    | 0.340 | 0.331  | **0.610** | 0.578           |
| FHB          | Lasso      | 0.185 | 0.022  | **0.430** | 0.390           |
| spikelet     | Lasso      | 0.350 | 0.872  | **0.599** | 0.549           |
| height       | Lasso      | 0.579 | 11.749 | **0.776** | 0.749           |
| FD           | XGBoost    | 0.432 | 1.982  | **0.670** | 0.595           |
| headingdate  | LightGBM   | 0.375 | 2.232  | **0.619** | 0.568           |
| spikelength  | XGBoost    | 0.195 | 0.864  | **0.469** | 0.544           |
| tkw          | Lasso      | 0.353 | 3.520  | **0.595** | 0.547           |
| kernelspikelet| LightGBM  | 0.353 | 0.207  | **0.600** | 0.600           |
| Mature       | XGBoost    | 0.328 | 1.269  | **0.578** | 0.551           |
| gns          | XGBoost    | 0.329 | 3.930  | **0.584** | 0.569           |
| cold         | XGBoost    | 0.262 | 0.115  | **0.514** | 0.495           |
| tiller       | Lasso      | 0.209 | 0.272  | **0.463** | 0.410           |
| yield        | LightGBM   | 0.430 | 38.971 | **0.657** | 0.613           |
| lodging      | Lasso      | 0.626 | 0.351  | **0.795** | 0.773           |

- CNN最佳PearsonR为该性状下所有SNP数中CNN的最大值。
- 表中PearsonR加粗为所有模型中最大值。

### 3.1.1 不同SNP数量下各模型综合评分

为更全面评价各模型在不同SNP数量下的整体表现，采用PearsonR归一化均值作为综合评分，结果如下：

| 模型/SNP数     | 100   | 1000  | 3000  | 5000  | 7000  |
|----------------|-------|-------|-------|-------|-------|
| **CNN**        | 0.41  | 0.48  | 0.48  | 0.54  | 0.56  |
| **Lasso**      | 0.62  | 0.67  | 0.67  | 0.70  | 0.71  |
| **XGBoost**    | 0.60  | 0.66  | 0.66  | 0.69  | 0.70  |
| **LightGBM**   | 0.59  | 0.65  | 0.65  | 0.68  | 0.69  |
| **RandomForest**| 0.58 | 0.64  | 0.64  | 0.67  | 0.68  |

> 注：数值为四舍五入后的小数，实际计算保留更多位。

**结论与解读：**
- CNN的综合评分在所有SNP数量下均低于传统模型，但随着SNP数量增加，评分有提升趋势。
- Lasso、XGBoost、LightGBM、RandomForest在各SNP数量下表现接近，且均优于CNN。
- SNP数量越多，所有模型的综合评分普遍提升，CNN提升幅度相对较大，但仍未超越传统模型。

### 3.2 CNN与传统模型对比分析

- **sterilspike**：CNN在R2和PearsonR上略低于LightGBM和XGBoost，表现中等。传统集成模型在此性状上更优。
- **FHB**：CNN表现不如Lasso和RandomForest，传统模型更适合该性状。
- **spikelet**：CNN与Lasso表现接近，但Lasso略优，传统线性模型在此性状上有优势。
- **height**：CNN表现与Lasso接近，但Lasso略优，传统模型在高维特征下表现更稳定。
- **FD**：XGBoost表现最佳，CNN略逊一筹，集成模型对该性状更敏感。
- **headingdate**：LightGBM和XGBoost表现优于CNN，传统模型更适合。
- **spikelength**：CNN与XGBoost表现接近，但XGBoost略优。
- **tkw**：Lasso和LightGBM表现优于CNN。
- **kernelspikelet**：LightGBM表现最佳，CNN次之。
- **Mature**：XGBoost表现最佳，CNN略低。
- **gns**：XGBoost表现最佳，CNN略低。
- **cold**：XGBoost表现最佳，CNN略低。
- **tiller**：Lasso表现最佳，CNN表现较差。
- **yield**：LightGBM和Lasso表现优于CNN。
- **lodging**：Lasso表现最佳，CNN次之。

**结论：**  
CNN在部分性状（如spikelet、kernelspikelet、lodging等）表现接近甚至优于部分传统模型，但整体来看，集成模型（LightGBM、XGBoost）和Lasso在大多数性状上表现更优。CNN的优势在于特征自动提取和对复杂非线性关系的建模，但在样本量有限或特征与性状关系较为线性时，传统模型更具优势。

## 4. 结果可视化建议

- 性状-模型性能热力图（可用seaborn绘制，横轴性状，纵轴模型，色阶为R2或PearsonR）
- 各模型在不同SNP数量下的性能曲线
- CNN网络结构图、训练损失曲线（引用`res/cnn/`目录下图片）

## 5. 总结与展望

- CNN模型在高维、复杂特征场景下有潜力，但需更大样本量和更深层网络结构以充分发挥优势。
- 传统集成模型和Lasso在当前数据集下表现更为稳定和优异，建议作为基线模型。
- 后续可尝试多模型融合、特征工程优化、深度网络结构改进等方向提升预测性能。

---

如需插入具体图片，请将`res/cnn/`目录下的结构图、训练曲线等图片插入对应章节。  
如需详细代码分析，可进一步参考`src/models/`目录下各模型实现文件。 